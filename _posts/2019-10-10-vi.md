---
layout: post
title: 变分推断
category: machine-learning
---

# 前言


# 变分法

泛函极值：

高数中，我们求极值，可以用$f'(x)=0$这个方法。
类比，在泛函中，如果一个函数满足**欧拉拉格朗日方程**，这个函数可以成为最大值的函数。


# 前导线性代数知识

只写泛函用到的一些前导线代基础概念：

[二次型相关概念](https://www.youtube.com/watch?v=Zrk3C26GC5E)

- 二次型：$x_1^2+3x_2^2-5x_3^2+4x_1x_2-8x_2x_3$，可写成$X^TAX$
- 标准型：$x_1^2+3x_2^2-5x_3^2$，只有2次项
- 规范性：$x_1^2+x_2^2-x_3^2$，标准型系数为$\pm1,0$

[特征向量相关概念](https://www.youtube.com/watch?v=gKbEW4LbqE4)

两个有意思的性质：

- $\sum\limits_{i=1}^n a_{ij} = \sum\limits_{i=1}^n \lambda_i$ :矩阵A主对角线的元素相加，等于，所有特征值相加
- $\|A\|=\prod\limits_{i=1}\lambda_i$：矩阵A行业式值，等于，所有行列式相乘

[相似对角化概念](https://www.bilibili.com/video/av68468820/)

相似：如果$PAP^{-1}=B$，则称$A~B$，即**A相似于B**。

相似对角化：如果$PAP^{-1}=\Lambda$，其中$\Lambda$是一个对角矩阵（就是只有对角线为非0，其余都是0），就称A可**相似对角化**。

[]

[参考]

- 远航君的线性代数讲座


# [泛函分析(孙炯)](https://www.bilibili.com/video/av20207040)

## 第一章

### 第一节

运算=算子，映射：空间⇒空间，泛函是从“变分、微分方程、积分方程、函数论、量子物理”综合基础上发展出来的。使用几何、代数的方法，研究无限维的函数、算子、极限。所谓几何，就是研究“垂直、距离、长度”，专业词汇“距离、范数、内积”

泛函，就是类比解析集合，那些点，就变成了函数，sin，cos。。。，但是给他们加上距离、范数、内积这些。这个时候函数变成了无穷维，泛函就变成了无穷维到无穷维的变换。既然是无穷维，收敛性就变得很重要了。“收敛性”是泛函中的一个最重要的问题。泛函研究方法，是尝试把有限维空间的方法搬过来。

**向量分解**

正交坐标系：$\vec{i}=(1,0,0),\vec{j}=(0,1,0),\vec{k}=(0,0,1)$

内积：$\vec{a} \cdot \vec{b} = (\vec{a},\vec{b})  = a_1 b_1 + a_2 b_2 + a_3 b_3 = \|\vec{a}\| \|\vec{b}\| \cdot cos(\theta)$
其中：$a_1 =( \vec{a_1},\vec{i}), a_2=(\vec{a_2},\vec{j}), a_3=(\vec{a_3},\vec{k})$

“投影”：可以表示为和单位向量的内积：$a(a1,a2,a3), 投影a1=(a,i), 投影a2=(a,j), 投影a3=(a,k)$，$i,j,k$是单位向量，$(a,k)$是内积。

模：$\|a\|=\sqrt{a_1^2 + a_2^2 + a_3^2}$

由上面的公式们，还可以进一步推导出：

$\vec{a} = a_1 \vec{i} + a_2 \vec{j} + a_3 \vec{k} = (\vec{a_1},\vec{i})\vec{i} + (\vec{a_2},\vec{j})\vec{j} + (\vec{a_3},\vec{k})\vec{k} $

$\|a\|^2=\sum\limits_{i=1}^n \|(\vec{a},\vec{e})\|$

****

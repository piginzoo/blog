---
layout: post
title: 语义分割网络:FCN,UNet
category: machine-learning
---

## 语义分割网络

研究语义分割，源于现在的文字检测和识别算法，为了提高正确率，要变态地去区分到像素级别，比如在EAST、PSENET、TextScanner等算法当中，都应用到语义分割网络。而语义分割网络，作为目标识别的重要算法，也确实非常重要，之前虽然看过，但是，不自己撸一篇文章，还是很容易遗忘很多细节，所以，写下此篇，把一些细节总结下来，他日可以快速回忆起来。

目前主要的语义分割网络，有很多种，如FCN、UNet、SegNet、DeepLab、RefineNet、PSPNet等等，我这里仅仅研究了FCN和UNet，其他的有时间再去看了。

作为一个工程党，我不会去研究论文细节和原理本质，而是更关注实现的细节。对这个领域感兴趣的同学，可以看一下这篇知乎上的[综述](https://zhuanlan.zhihu.com/p/68147183)，快速了解一下这个领域。


## FCN（Full Convolutional Network） 全卷积网络

先贴论文地址：[Fully Convolutional Networks for Semantic Segmentation](https://arxiv.org/abs/1411.4038)

**名字由来**：这名很容易和FCN（Full Connection Network）- 全连接网络混淆啊。其实，全卷积网络就是为了避免全连接网络的弊端（比如必须固定尺寸，比如全连接层参数过度哦，不得不用dropout这类手段防止过拟合啥的），改进成，所有的位置都使用卷积网络，避免使用全链接。这名就是这么来的。他不像全连接那样，把图像全部拉平，所以，还可以保持图像的空间结构。

全卷积网络三大件：
- 全卷积化（Convolutionalization）：跟之前差不多，但是去掉了全连接层
- 反卷积（Deconvolution）：用在把小的feature map上采样上去
- 跳层结构（Skip Layer）：

### 反卷积

原始经过卷基层，如VGG或者ResNet后，变成了1/32 x 1/32大小，缩小了32倍，我们为了做语义分割，肯定是要把他还原成原图大小，这样才好判断每个像素的分类。

如何把小的feature map变成原图的大小，最简单的办法是①[线性插值](https://zhuanlan.zhihu.com/p/34492145)，或者用②[反池化](https://blog.csdn.net/chengqiuming/article/details/80300284)，但是这种过于简单粗暴，还有一个更好一些的办法，就是通过③“反卷积”，需要使用一个的卷积核，来帮着变大。到底如何做呢？看下图：

![](/images/20200423/dconv1.gif){:class="myimg30"}
![](/images/20200423/dconv2.gif){:class="myimg30"}

一图胜千言，如上图，下方是反卷积之前的输入的feature map，阴影是反卷积核，上面深绿色的是反卷积后的结果，因为原图小，所以要给他加padding（白色），这样就引出反卷积的两种方式（上图所示）。第二种更常用。可以读一下[知乎](https://www.zhihu.com/question/48279880)上的这篇文章，了解更多细节。

### 跳层

如果只把最后一层（如何pool5，原图1/32）直接上卷积，会丧失很多细节，所以，最好是把之前的卷积层（如pool4，甚至pool3）的信息也揉到一起，这件事就叫做跳层（skip-layer）。

![](/images/20200423/1587645084082.jpg){:class="myimg100"}

[参考](https://blog.csdn.net/justpsss/article/details/77170004)：
>这里用的是VGG为例，pool1到pool5是五个最大池化层，因此图中的pool5层的大小是原图image的1/32（1/251/25），最粗糙的做法就是直接把pool5层进行步长为32的上采样（逆卷积），一步得到跟原图一样大小的概率图（fcn-32s)。但是这样做会丢失掉很多浅层的特征，尤其是浅层特征往往包含跟多的位置信息，所以我们需要把浅层的特征加上来，作者这里做法很简单，就是直接“加”上来，求和操作，也就完成了跳跃融合。也就是先将pool5层进行步长为2的上采样，然后加上pool4层的特征（这里pool4层后面跟了一个改变维度的卷积层，卷积核初始化为0），之后再进行一次步长为16的上采样得到原图大小的概率图即可（fcn-16s）。另外fcn-8s也是同样的做法，至于后面为什么没有fcn-4s、fcn-2s，我认为是因为太浅层的特征实际上不具有泛化性，加上了也没什么用，反而会使效果变差，所以作者也没继续下去了。

上图中$\color{red}{红色}$是反卷积，而$\color{green}{绿色}$是双线性插值。

另外，
- **FCN-16s**就是pool4+pool5的信息，柔和到一起
- **FCN-8s**就是pool3+pool4+pool5的信息，柔和到了一起

### ResNET50的FCN

FCN的backbone可以是任何主流的backbone，常用的ResNet50应该是怎么样的呢？我们来详细说说。

首先，可以看看Resnet50的结构，我们都知道Resnet50就比较深了，为了防止梯度小时，设计了shortcut结构。

好，可以先看看Resnet50的详细结构，[参见这篇](https://blog.csdn.net/nima1994/article/details/82686132)。

不过这个太复杂了，我们找个简化版本的：

![](/images/20200427/1587970014152.jpg){:class="myimg"}

我们最关心的是他什么时候feature map缩小一倍，如图所示，我标识到了上图中。

为什么是这些位置了，具体可以参考[这篇](https://blog.csdn.net/qq_25491201/article/details/78405549)
```
	#conv1 ->1/2 , 1/4
	x = Conv2d_BN(x, nb_filter=64, kernel_size=(7, 7), strides=(2, 2), padding='valid')
	x = MaxPooling2D(pool_size=(3, 3), strides=(2, 2), padding='same')(x)

	#conv3_x ->1/8
	x = identity_Block(x, nb_filter=128, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True) 

	#conv4_x ->1/16
	x = identity_Block(x, nb_filter=256, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)
	
	#conv5_x ->1/32
	x = identity_Block(x, nb_filter=512, kernel_size=(3, 3), strides=(2, 2), with_conv_shortcut=True)
```
**Identity_Block**,*是Resnet设计的一个可重复的卷基层，由3组个卷积、BatchNormal、Relu激活组成，就是上图中中括弧表示的内容。*

但是，我们不是直接在它刚刚变成1/2的地方就取出来去做FCN，而是在上图中的逻辑层**Conv?_x**的输出，也就是最后一个Relu激活函数后输出。另外，我们FCN其实只用到后3层的输出，也就是`Conv3_x、Conv4_x、Conv5_x`的输出，对应的在一般的pretrain的Resnet50的层的命名中，对应着`activate_22,activate_40,activation_49`三处。详细位置和标号，可以参见[这张图](https://img-blog.csdn.net/20180913122255454?watermark/2/text/aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L25pbWExOTk0/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70)。

## UNet

未完待续...
---
layout: post
title: OCR 实践笔记
category: machine-learning
---

# 概述

从春节后，就着手这个项目，从开始研究，到上手代码，到样本生成，到真实样本采集等，经历了整个过程，已经2个月了，项目也基本上完成的差不多了，开一个帖子，把自己的项目中的点滴记录下来。

# CTPN

## 代码库

我最终选择的是[eragonruan](https://github.com/eragonruan/text-detection-ctpn)的版本，fork了一份，放到了我的[github](https://github.com/piginzoo/text-detection-ctpn)上，但是CTPN确实有不少问题，如果让我重新选择的话，我可能会选择EAST或者PSNet。特别是PSNet，有个QQ群【785515057】，群主就是复现[PSNet代码](https://github.com/liuheng92/tensorflow_PSENet)的“晓恒”，群里面也非常友爱互助，真后悔没有早点遇到这群人。不过，CTPN是一个保守选择，对我们的场景，是够用的了。我也没时间再去研究PSNet了，也只有这样了，下个项目或者二期的时候，我会去再选择PSNet了。

另外，我fork的版本修改了和增加了狠多内容，包括：
- 重写了训练数据生成的部分，基本上是从头写的了
- 重构了样本split的代码
- 修改了样本加载机制，没有用TFRecord，而是用的shuffle_batch的方式
- 重构了训练代码，加入了早停、Validate验证等
- 重构了预测代码
- 修改了很多细节，模型细节，训练细节等

网络结构没有什么变化，还是vgg做为backbone，然后接一个LSTM，全连接后，做一个anchor的正负例和回归预测。不过，这些代码里面，增加了大量的注释，都是我对代码的理解，特别是核心类anchor_target_layer.py，由于注释太多，我都惨不忍睹了，只好备份一下注释版，然后删除掉注释，整了一个整洁版。

## 修改细节

### 样本数据生成

[generator.py](https://github.com/piginzoo/text-detection-ctpn/blob/banjin-dev/data_generator/generator.py)

# CRNN

# 集成

